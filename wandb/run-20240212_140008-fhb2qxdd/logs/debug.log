2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Current SDK version is 0.16.1
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Configure stats pid to 59086
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/.config/wandb/settings
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/settings
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_init.py:_log_setup():524] Logging user logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240212_140008-fhb2qxdd/logs/debug.log
2024-02-12 14:00:08,438 INFO    MainThread:59086 [wandb_init.py:_log_setup():525] Logging internal logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240212_140008-fhb2qxdd/logs/debug-internal.log
2024-02-12 14:00:08,439 INFO    MainThread:59086 [wandb_init.py:init():564] calling init triggers
2024-02-12 14:00:08,440 INFO    MainThread:59086 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'model': ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=10, out_features=10, bias=True)
), 'bias': True, 'ETF_fc': True, 'fixdim': 1, 'SOTA': True, 'width': 32, 'depth': 6, 'gpu_id': 0, 'seed': 6, 'use_cudnn': True, 'dataset': 'cifar10', 'data_dir': '~/data', 'uid': 'resnet18-design-LBFGS', 'force': True, 'epochs': 1, 'batch_size': 2048, 'loss': 'CrossEntropy', 'sample_size': None, 'lr': 0.1, 'optimizer': 'LBFGS', 'history_size': 10, 'device': 'mps'}
2024-02-12 14:00:08,440 INFO    MainThread:59086 [wandb_init.py:init():589] re-initializing run, found existing run on stack: z2gqyf2m
2024-02-12 14:00:08,442 INFO    MainThread:59086 [wandb_run.py:_finish():1962] finishing run data-distillation-with-nc/DD&NC/z2gqyf2m
2024-02-12 14:00:08,442 INFO    MainThread:59086 [jupyter.py:save_history():445] not saving jupyter history
2024-02-12 14:00:08,442 INFO    MainThread:59086 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2024-02-12 14:00:08,443 INFO    MainThread:59086 [wandb_init.py:_jupyter_teardown():452] cleaning up jupyter logic
2024-02-12 14:00:08,443 INFO    MainThread:59086 [wandb_run.py:_atexit_cleanup():2202] got exitcode: 0
2024-02-12 14:00:08,443 INFO    MainThread:59086 [wandb_run.py:_restore():2185] restore
2024-02-12 14:00:08,443 INFO    MainThread:59086 [wandb_run.py:_restore():2191] restore done
2024-02-12 14:00:19,357 INFO    MainThread:59086 [wandb_run.py:_footer_history_summary_info():3837] rendering history
2024-02-12 14:00:19,358 INFO    MainThread:59086 [wandb_run.py:_footer_history_summary_info():3869] rendering summary
2024-02-12 14:00:19,369 INFO    MainThread:59086 [wandb_run.py:_footer_sync_info():3796] logging synced files
2024-02-12 14:00:19,468 INFO    MainThread:59086 [wandb_init.py:init():614] starting backend
2024-02-12 14:00:19,468 INFO    MainThread:59086 [wandb_init.py:init():618] setting up manager
2024-02-12 14:00:19,471 INFO    MainThread:59086 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2024-02-12 14:00:19,471 INFO    MainThread:59086 [wandb_init.py:init():624] backend started and connected
2024-02-12 14:00:19,483 INFO    MainThread:59086 [wandb_run.py:_label_probe_notebook():1294] probe notebook
2024-02-12 14:00:19,483 INFO    MainThread:59086 [wandb_run.py:_label_probe_notebook():1304] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2024-02-12 14:00:19,484 INFO    MainThread:59086 [wandb_init.py:init():716] updated telemetry
2024-02-12 14:00:19,517 INFO    MainThread:59086 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2024-02-12 14:00:20,939 INFO    MainThread:59086 [wandb_run.py:_on_init():2254] communicating current version
2024-02-12 14:00:21,109 INFO    MainThread:59086 [wandb_run.py:_on_init():2263] got version response upgrade_message: "wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-02-12 14:00:21,110 INFO    MainThread:59086 [wandb_init.py:init():800] starting run threads in backend
2024-02-12 14:00:24,793 INFO    MainThread:59086 [wandb_run.py:_console_start():2233] atexit reg
2024-02-12 14:00:24,793 INFO    MainThread:59086 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2024-02-12 14:00:24,793 INFO    MainThread:59086 [wandb_run.py:_redirect():2153] Wrapping output streams.
2024-02-12 14:00:24,793 INFO    MainThread:59086 [wandb_run.py:_redirect():2178] Redirects installed.
2024-02-12 14:00:24,794 INFO    MainThread:59086 [wandb_init.py:init():841] run started, returning control to user process
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Current SDK version is 0.16.1
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Configure stats pid to 59086
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/.config/wandb/settings
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/settings
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_init.py:_log_setup():524] Logging user logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240212_140225-g5eiomax/logs/debug.log
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_init.py:_log_setup():525] Logging internal logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240212_140225-g5eiomax/logs/debug-internal.log
2024-02-12 14:02:25,315 INFO    MainThread:59086 [wandb_init.py:_jupyter_setup():470] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x292a9dc10>
2024-02-12 14:02:25,316 INFO    MainThread:59086 [wandb_init.py:init():564] calling init triggers
2024-02-12 14:02:25,316 INFO    MainThread:59086 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'model': ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=10, out_features=10, bias=True)
), 'bias': True, 'ETF_fc': True, 'fixdim': 1, 'SOTA': True, 'width': 32, 'depth': 6, 'gpu_id': 0, 'seed': 6, 'use_cudnn': True, 'dataset': 'cifar10', 'data_dir': '~/data', 'uid': 'resnet18-design-LBFGS', 'force': True, 'epochs': 1, 'batch_size': 1024, 'loss': 'CrossEntropy', 'sample_size': None, 'lr': 0.1, 'optimizer': 'LBFGS', 'history_size': 10, 'device': 'mps'}
2024-02-12 14:02:25,316 INFO    MainThread:59086 [wandb_init.py:init():589] re-initializing run, found existing run on stack: fhb2qxdd
2024-02-12 14:02:25,318 INFO    MainThread:59086 [wandb_run.py:_finish():1962] finishing run data-distillation-with-nc/DD&NC/fhb2qxdd
2024-02-12 14:02:25,318 INFO    MainThread:59086 [wandb_run.py:_atexit_cleanup():2202] got exitcode: 0
2024-02-12 14:02:25,318 INFO    MainThread:59086 [wandb_run.py:_restore():2185] restore
2024-02-12 14:02:25,319 INFO    MainThread:59086 [wandb_run.py:_restore():2191] restore done
2024-02-12 14:02:30,098 INFO    MainThread:59086 [wandb_run.py:_footer_history_summary_info():3837] rendering history
2024-02-12 14:02:30,098 INFO    MainThread:59086 [wandb_run.py:_footer_history_summary_info():3869] rendering summary
2024-02-12 14:02:30,105 INFO    MainThread:59086 [wandb_run.py:_footer_sync_info():3796] logging synced files
