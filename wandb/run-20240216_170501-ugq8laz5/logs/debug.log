2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Current SDK version is 0.16.3
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Configure stats pid to 85592
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/.config/wandb/settings
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/settings
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_init.py:_log_setup():526] Logging user logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240216_170501-ugq8laz5/logs/debug.log
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_init.py:_log_setup():527] Logging internal logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240216_170501-ugq8laz5/logs/debug-internal.log
2024-02-16 17:05:01,116 INFO    MainThread:85592 [wandb_init.py:init():566] calling init triggers
2024-02-16 17:05:01,117 INFO    MainThread:85592 [wandb_init.py:init():573] wandb.init called with sweep_config: {}
config: {'model': ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=10, out_features=10, bias=True)
), 'bias': True, 'ETF_fc': True, 'fixdim': 1, 'SOTA': False, 'width': 32, 'depth': 6, 'gpu_id': 0, 'seed': 6, 'use_cudnn': True, 'dataset': 'cifar10', 'data_dir': '~/data', 'uid': 'tmp', 'force': True, 'epochs': 200, 'batch_size': 64, 'loss': 'CrossEntropy', 'sample_size': None, 'lr': 0.1, 'optimizer': 'LBFGS', 'device': device(type='mps')}
2024-02-16 17:05:01,117 INFO    MainThread:85592 [wandb_init.py:init():591] re-initializing run, found existing run on stack: gssqjugw
2024-02-16 17:05:01,120 INFO    MainThread:85592 [wandb_run.py:_finish():1970] finishing run data-distillation-with-nc/DD&NC/gssqjugw
2024-02-16 17:05:01,121 INFO    MainThread:85592 [jupyter.py:save_history():445] not saving jupyter history
2024-02-16 17:05:01,121 INFO    MainThread:85592 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2024-02-16 17:05:01,121 INFO    MainThread:85592 [wandb_init.py:_jupyter_teardown():454] cleaning up jupyter logic
2024-02-16 17:05:01,121 INFO    MainThread:85592 [wandb_run.py:_atexit_cleanup():2210] got exitcode: 0
2024-02-16 17:05:01,121 INFO    MainThread:85592 [wandb_run.py:_restore():2193] restore
2024-02-16 17:05:01,122 INFO    MainThread:85592 [wandb_run.py:_restore():2199] restore done
2024-02-16 17:05:19,038 INFO    MainThread:85592 [wandb_run.py:_footer_history_summary_info():3866] rendering history
2024-02-16 17:05:19,040 INFO    MainThread:85592 [wandb_run.py:_footer_history_summary_info():3898] rendering summary
2024-02-16 17:05:19,058 INFO    MainThread:85592 [wandb_run.py:_footer_sync_info():3825] logging synced files
2024-02-16 17:05:19,216 INFO    MainThread:85592 [wandb_init.py:init():616] starting backend
2024-02-16 17:05:19,216 INFO    MainThread:85592 [wandb_init.py:init():620] setting up manager
2024-02-16 17:05:19,221 INFO    MainThread:85592 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2024-02-16 17:05:19,222 INFO    MainThread:85592 [wandb_init.py:init():628] backend started and connected
2024-02-16 17:05:19,240 INFO    MainThread:85592 [wandb_run.py:_label_probe_notebook():1295] probe notebook
2024-02-16 17:05:19,241 INFO    MainThread:85592 [wandb_run.py:_label_probe_notebook():1305] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2024-02-16 17:05:19,241 INFO    MainThread:85592 [wandb_init.py:init():720] updated telemetry
2024-02-16 17:05:19,301 INFO    MainThread:85592 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-02-16 17:05:20,688 INFO    MainThread:85592 [wandb_run.py:_on_init():2262] communicating current version
2024-02-16 17:05:21,024 INFO    MainThread:85592 [wandb_run.py:_on_init():2271] got version response 
2024-02-16 17:05:21,024 INFO    MainThread:85592 [wandb_init.py:init():804] starting run threads in backend
2024-02-16 17:05:24,939 INFO    MainThread:85592 [wandb_run.py:_console_start():2241] atexit reg
2024-02-16 17:05:24,939 INFO    MainThread:85592 [wandb_run.py:_redirect():2096] redirect: wrap_raw
2024-02-16 17:05:24,939 INFO    MainThread:85592 [wandb_run.py:_redirect():2161] Wrapping output streams.
2024-02-16 17:05:24,939 INFO    MainThread:85592 [wandb_run.py:_redirect():2186] Redirects installed.
2024-02-16 17:05:24,939 INFO    MainThread:85592 [wandb_init.py:init():847] run started, returning control to user process
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Current SDK version is 0.16.3
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Configure stats pid to 85592
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/.config/wandb/settings
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Loading settings from /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/settings
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_init.py:_log_setup():526] Logging user logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240216_175100-iuxqrdqd/logs/debug.log
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_init.py:_log_setup():527] Logging internal logs to /Users/songzeyang/Documents/GitHub/Data_Distill_with_NC/wandb/run-20240216_175100-iuxqrdqd/logs/debug-internal.log
2024-02-16 17:51:00,914 INFO    MainThread:85592 [wandb_init.py:_jupyter_setup():472] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x167209a10>
2024-02-16 17:51:00,916 INFO    MainThread:85592 [wandb_init.py:init():566] calling init triggers
2024-02-16 17:51:00,917 INFO    MainThread:85592 [wandb_init.py:init():573] wandb.init called with sweep_config: {}
config: {'model': ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=10, out_features=10, bias=True)
), 'bias': True, 'ETF_fc': True, 'fixdim': 1, 'SOTA': False, 'width': 32, 'depth': 6, 'gpu_id': 0, 'seed': 6, 'use_cudnn': True, 'dataset': 'cifar10', 'data_dir': '~/data', 'uid': 'tmp', 'force': True, 'epochs': 200, 'batch_size': 64, 'loss': 'CrossEntropy', 'sample_size': None, 'lr': 0.1, 'optimizer': 'LBFGS', 'device': device(type='mps')}
2024-02-16 17:51:00,917 INFO    MainThread:85592 [wandb_init.py:init():591] re-initializing run, found existing run on stack: ugq8laz5
2024-02-16 17:51:00,919 INFO    MainThread:85592 [wandb_run.py:_finish():1970] finishing run data-distillation-with-nc/DD&NC/ugq8laz5
2024-02-16 17:51:00,919 INFO    MainThread:85592 [wandb_run.py:_atexit_cleanup():2210] got exitcode: 0
2024-02-16 17:51:00,919 INFO    MainThread:85592 [wandb_run.py:_restore():2193] restore
2024-02-16 17:51:00,920 INFO    MainThread:85592 [wandb_run.py:_restore():2199] restore done
2024-02-16 17:51:33,073 INFO    MainThread:85592 [wandb_run.py:_footer_history_summary_info():3866] rendering history
2024-02-16 17:51:33,075 INFO    MainThread:85592 [wandb_run.py:_footer_history_summary_info():3898] rendering summary
2024-02-16 17:51:33,086 INFO    MainThread:85592 [wandb_run.py:_footer_sync_info():3825] logging synced files
