{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e0e813",
   "metadata": {},
   "source": [
    "# Hyperparameter Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54880c",
   "metadata": {},
   "source": [
    "This notebook implements an hyperparameter sweep for data distillation algorithm utilizing the recent finding in neural collapse. \n",
    "\n",
    "The main papers considered here are \n",
    " - data distillation:\n",
    "     - https://github.com/SsnL/dataset-distillation \n",
    "     - https://github.com/google-research/google-research/tree/master/kip\n",
    " - Neural Collapse:\n",
    "     - https://github.com/tding1/Neural-Collapse. \n",
    "\n",
    "The neural network has the option to fix the last layer weight matrix to be a simplex ETF. The ETF is a benign optimization landscape empeirically observed in practice as long as the network enters its terminal phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768c8e0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45618fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd64322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aace5",
   "metadata": {},
   "source": [
    "Let's import the file from the https://github.com/tding1/Neural-Collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "988e1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from models.res_adapt import ResNet18_adapt\n",
    "from utils import *\n",
    "\n",
    "from train_2nd_order import weight_decay, trainer\n",
    "from validate_NC import compute_Wh_b_relation, compute_W_H_relation, compute_ETF, compute_Sigma_B, compute_Sigma_W,compute_info,FCFeatures\n",
    "\n",
    "from data.datasets import make_dataset\n",
    "from arg_loader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14274f5",
   "metadata": {},
   "source": [
    "# Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1c9e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture params\n",
    "model='resnet18'\n",
    "bias=True\n",
    "ETF_fc=False\n",
    "fixdim=0\n",
    "SOTA=False\n",
    "\n",
    "# MLP settings (only when using mlp and res_adapt(in which case only width has effect))\n",
    "width=1024\n",
    "depth=6\n",
    "\n",
    "# hardware settings\n",
    "gpu_id=0\n",
    "seed=6\n",
    "use_cudnn=True\n",
    "\n",
    "# dataset\n",
    "dataset='cifar10'\n",
    "data_dir='~/data'\n",
    "uid=\"tmp\"\n",
    "force=True\n",
    "\n",
    "# learning options\n",
    "epochs = 2\n",
    "batch_size=32\n",
    "loss = 'CrossEntropy'\n",
    "sample_size = None\n",
    "\n",
    "# optimization\n",
    "lr=0.05\n",
    "optimizer = \"SGD\"\n",
    "history_size=10\n",
    "device = \"mps\"\n",
    "check = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b3e386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "override this uidtmp\n",
      "<arg_loader.train_args object at 0x296311010>\n",
      "cudnn is used\n"
     ]
    }
   ],
   "source": [
    "args = train_args(model=model,bias=bias,ETF_fc=ETF_fc,fixdim=fixdim,SOTA=SOTA,\n",
    "                  width=width,depth=depth,\n",
    "                  gpu_id=gpu_id,seed=seed,use_cudnn=use_cudnn,\n",
    "                  dataset=dataset,data_dir=data_dir,uid=uid,force=force,\n",
    "                  epochs=epochs,batch_size = batch_size,loss = loss,sample_size=sample_size,\n",
    "                  lr = lr,optimizer=optimizer,history_size=history_size, \n",
    "                  device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f27ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "if check:\n",
    "    torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45197578",
   "metadata": {},
   "source": [
    "# Define function to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b50e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(args, model, trainloader, epoch_id, criterion, optimizer):\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "\n",
    "        inputs, targets = inputs.to(args.device), targets.to(args.device)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        def closure():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if args.loss == 'CrossEntropy':\n",
    "                loss = criterion(outputs[0], targets) + weight_decay(args, model)\n",
    "            elif args.loss == 'MSE':\n",
    "                loss = criterion(outputs[0], nn.functional.one_hot(targets).type(torch.FloatTensor).to(args.device)) \\\n",
    "                       + weight_decay(args, model)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        model.eval()\n",
    "        outputs = model(inputs)\n",
    "        prec1, prec5 = compute_accuracy(outputs[0].data, targets.data, topk=(1, 5))\n",
    "\n",
    "        if args.loss == 'CrossEntropy':\n",
    "            loss = criterion(outputs[0], targets) + weight_decay(args, model)\n",
    "        elif args.loss == 'MSE':\n",
    "            loss = criterion(outputs[0], nn.functional.one_hot(targets).type(torch.FloatTensor).to(args.device)) \\\n",
    "                   + weight_decay(args, model)\n",
    "\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1.item(), inputs.size(0))\n",
    "        top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "        # if batch_idx % 10 == 0:\n",
    "        print('[epoch: %d] (%d/%d) | Loss: %.4f | top1: %.4f | top5: %.4f ' %\n",
    "              (epoch_id + 1, batch_idx + 1, len(trainloader), losses.avg, top1.avg, top5.avg))\n",
    "                \n",
    "    \n",
    "#     wandb.log({\n",
    "#         \"losses.avg\":losses.avg, \n",
    "#         \"top1.avg\":top1.avg,\n",
    "#         \"top5.avg\":top5.avg\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "273ec6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NC(args,model,testloader):\n",
    "    \n",
    "    args.load_path = \"model_weights/tmp/\"\n",
    "\n",
    "    if args.load_path is None:\n",
    "        sys.exit('Need to input the path to a pre-trained model!')\n",
    "\n",
    "    fc_features = FCFeatures()\n",
    "    model.fc.register_forward_pre_hook(fc_features)\n",
    "    info_dict = {\n",
    "            'collapse_metric': [],\n",
    "            'ETF_metric': [],\n",
    "            'WH_relation_metric': [],\n",
    "            'Wh_b_relation_metric': [],\n",
    "            'W': [],\n",
    "            'b': [],\n",
    "            'H': [],\n",
    "            'mu_G_train': [],\n",
    "            # 'mu_G_test': [],\n",
    "            'train_acc1': [],\n",
    "            'train_acc5': [],\n",
    "            'test_acc1': [],\n",
    "            'test_acc5': []\n",
    "        }\n",
    "\n",
    "    logfile = open('%s/test_log.txt' % (args.load_path), 'w')\n",
    "    for i in range(args.epochs):\n",
    "\n",
    "        model.load_state_dict(torch.load(args.load_path + 'epoch_' + str(i + 1).zfill(3) + '.pth'))\n",
    "        model.eval()\n",
    "\n",
    "        for n, p in model.named_parameters():\n",
    "            if 'fc.weight' in n:\n",
    "                W = p\n",
    "            if 'fc.bias' in n:\n",
    "                b = p\n",
    "\n",
    "        mu_G_train, mu_c_dict_train, train_acc1, train_acc5 = compute_info(args, model, fc_features, trainloader, isTrain=True)\n",
    "        mu_G_test, mu_c_dict_test, test_acc1, test_acc5 = compute_info(args, model, fc_features, testloader, isTrain=False)\n",
    "\n",
    "        Sigma_W = compute_Sigma_W(args, model, fc_features, mu_c_dict_train, trainloader, isTrain=True)\n",
    "        # Sigma_W_test_norm = compute_Sigma_W(args, model, fc_features, mu_c_dict_train, testloader, isTrain=False)\n",
    "        Sigma_B = compute_Sigma_B(mu_c_dict_train, mu_G_train)\n",
    "\n",
    "        collapse_metric = np.trace(Sigma_W @ scilin.pinv(Sigma_B)) / len(mu_c_dict_train)\n",
    "        ETF_metric = compute_ETF(W)\n",
    "        WH_relation_metric, H = compute_W_H_relation(W, mu_c_dict_train, mu_G_train)\n",
    "        if args.bias:\n",
    "            Wh_b_relation_metric = compute_Wh_b_relation(W, mu_G_train, b)\n",
    "        else:\n",
    "            Wh_b_relation_metric = compute_Wh_b_relation(W, mu_G_train, torch.zeros((W.shape[0], )))\n",
    "\n",
    "        info_dict['collapse_metric'].append(collapse_metric)\n",
    "        info_dict['ETF_metric'].append(ETF_metric)\n",
    "        info_dict['WH_relation_metric'].append(WH_relation_metric)\n",
    "        info_dict['Wh_b_relation_metric'].append(Wh_b_relation_metric)\n",
    "\n",
    "        info_dict['W'].append((W.detach().cpu().numpy()))\n",
    "        if args.bias:\n",
    "            info_dict['b'].append(b.detach().cpu().numpy())\n",
    "        info_dict['H'].append(H.detach().cpu().numpy())\n",
    "\n",
    "        info_dict['mu_G_train'].append(mu_G_train.detach().cpu().numpy())\n",
    "        # info_dict['mu_G_test'].append(mu_G_test.detach().cpu().numpy())\n",
    "\n",
    "        info_dict['train_acc1'].append(train_acc1)\n",
    "        info_dict['train_acc5'].append(train_acc5)\n",
    "        info_dict['test_acc1'].append(test_acc1)\n",
    "        info_dict['test_acc5'].append(test_acc5)\n",
    "\n",
    "        \n",
    "\n",
    "    print_and_save('[epoch: %d] | train top1: %.4f | train top5: %.4f | test top1: %.4f | test top5: %.4f ' %\n",
    "                    (i + 1, train_acc1, train_acc5, test_acc1, test_acc5), logfile)\n",
    "    \n",
    "    wandb.log({\n",
    "                   \"train_acc1\":train_acc1, \n",
    "                   \"train_acc5\":train_acc5,\n",
    "                   \"test_acc1\":test_acc1,\n",
    "                   \"test_acc5\":test_acc5\n",
    "                })\n",
    "    \n",
    "    wandb.log({\"collapse_metric\":collapse_metric, \n",
    "                   \"ETF_metric\":ETF_metric, \n",
    "                   \"WH_relation_metric\":WH_relation_metric,\n",
    "                   \"Wh_b_relation_metric\":Wh_b_relation_metric\n",
    "                })\n",
    "\n",
    "\n",
    "    with open(args.load_path + 'info.pkl', 'wb') as f:\n",
    "        pickle.dump(info_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cfb2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluater_NC(args,model,testloader,fc_features,info_dict):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "        if 'fc.weight' in n:\n",
    "            W = p\n",
    "        if 'fc.bias' in n:\n",
    "            b = p\n",
    "\n",
    "    mu_G_train, mu_c_dict_train, train_acc1, train_acc5 = compute_info(args, model, fc_features, trainloader, isTrain=True)\n",
    "    mu_G_test, mu_c_dict_test, test_acc1, test_acc5 = compute_info(args, model, fc_features, testloader, isTrain=False)\n",
    "\n",
    "    Sigma_W = compute_Sigma_W(args, model, fc_features, mu_c_dict_train, trainloader, isTrain=True)\n",
    "    # Sigma_W_test_norm = compute_Sigma_W(args, model, fc_features, mu_c_dict_train, testloader, isTrain=False)\n",
    "    Sigma_B = compute_Sigma_B(mu_c_dict_train, mu_G_train)\n",
    "\n",
    "    collapse_metric = np.trace(Sigma_W @ scilin.pinv(Sigma_B)) / len(mu_c_dict_train)\n",
    "    ETF_metric = compute_ETF(W)\n",
    "    WH_relation_metric, H = compute_W_H_relation(W, mu_c_dict_train, mu_G_train)\n",
    "    if args.bias:\n",
    "        Wh_b_relation_metric = compute_Wh_b_relation(W, mu_G_train, b)\n",
    "    else:\n",
    "        Wh_b_relation_metric = compute_Wh_b_relation(W, mu_G_train, torch.zeros((W.shape[0], )))\n",
    "\n",
    "    info_dict['collapse_metric'].append(collapse_metric)\n",
    "    info_dict['ETF_metric'].append(ETF_metric)\n",
    "    info_dict['WH_relation_metric'].append(WH_relation_metric)\n",
    "    info_dict['Wh_b_relation_metric'].append(Wh_b_relation_metric)\n",
    "\n",
    "    info_dict['W'].append((W.detach().cpu().numpy()))\n",
    "    if args.bias:\n",
    "        info_dict['b'].append(b.detach().cpu().numpy())\n",
    "    info_dict['H'].append(H.detach().cpu().numpy())\n",
    "\n",
    "    info_dict['mu_G_train'].append(mu_G_train.detach().cpu().numpy())\n",
    "    # info_dict['mu_G_test'].append(mu_G_test.detach().cpu().numpy())\n",
    "\n",
    "    info_dict['train_acc1'].append(train_acc1)\n",
    "    info_dict['train_acc5'].append(train_acc5)\n",
    "    info_dict['test_acc1'].append(test_acc1)\n",
    "    info_dict['test_acc5'].append(test_acc5)\n",
    "\n",
    "        \n",
    "\n",
    "    print_and_save('[epoch: %d] | train top1: %.4f | train top5: %.4f | test top1: %.4f | test top5: %.4f ' %\n",
    "                    (i + 1, train_acc1, train_acc5, test_acc1, test_acc5), logfile)\n",
    "    \n",
    "#     wandb.log({\n",
    "#                    \"train_acc1\":train_acc1, \n",
    "#                    \"train_acc5\":train_acc5,\n",
    "#                    \"test_acc1\":test_acc1,\n",
    "#                    \"test_acc5\":test_acc5\n",
    "#                 })\n",
    "    \n",
    "#     wandb.log({\"collapse_metric\":collapse_metric, \n",
    "#                    \"ETF_metric\":ETF_metric, \n",
    "#                    \"WH_relation_metric\":WH_relation_metric,\n",
    "#                    \"Wh_b_relation_metric\":Wh_b_relation_metric\n",
    "#                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d33b0d",
   "metadata": {},
   "source": [
    "# Set up a sweep configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786e3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\" : \"random\"\n",
    "}\n",
    "\n",
    "metric = {\n",
    "    \"name\": \"loss\",\n",
    "    \"goal\": \"minimize\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f6aa1",
   "metadata": {},
   "source": [
    "Set up parameters to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2028abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    \"learning_rate\":{\n",
    "        \"values\": [0.1,0.05,0.001]\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"values\": [\"Adam\",\"SGD\",\"LBFGS\"]\n",
    "    },\n",
    "#     \"width\":{\n",
    "#         \"values\": [1024,2048,4096]\n",
    "#     },\n",
    "#     \"depth\":{\n",
    "#         \"values\": [4,8,12]\n",
    "#     },\n",
    "    \"batch_size\":{\n",
    "        \"values\":[32,64,256,2048]\n",
    "    }\n",
    "}\n",
    "\n",
    "parameters_dict.update({\n",
    "    \"model\":{\n",
    "        \"values\": [\"resnet18\"]\n",
    "    },\n",
    "    \"epochs\":{\n",
    "        \"value\": 200\n",
    "    },\n",
    "    \"loss\":{\n",
    "        \"value\":'CrossEntropy'\n",
    "    }\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d84186",
   "metadata": {},
   "source": [
    "# Start sweep agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "186b8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: diryez1w\n",
      "Sweep URL: https://wandb.ai/data-distillation-with-nc/hyper_sweep_4_opt_para/sweeps/diryez1w\n"
     ]
    }
   ],
   "source": [
    "sweep_config[\"metric\"]=metric\n",
    "sweep_config[\"parameters\"]=parameters_dict\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyper_sweep_4_opt_para\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceb2f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(arg):\n",
    "    \n",
    "    trainloader, testloader, num_classes = make_dataset(arg.dataset, \n",
    "                                           arg.data_dir, \n",
    "                                           arg.batch_size, \n",
    "                                           SOTA=arg.SOTA)\n",
    "    \n",
    "    if args.model == \"MLP\":\n",
    "        model = models.__dict__[args.model](hidden = args.width, depth = args.depth, fc_bias=args.bias, num_classes=num_classes).to(args.device)\n",
    "    elif args.model == \"ResNet18_adapt\":\n",
    "        model = ResNet18_adapt(width = args.width, num_classes=num_classes, fc_bias=args.bias).to(args.device)\n",
    "    else:\n",
    "        model = models.__dict__[args.model](num_classes=num_classes, fc_bias=args.bias, ETF_fc=args.ETF_fc, fixdim=args.fixdim, SOTA=args.SOTA).to(args.device)\n",
    "\n",
    "    print('# of model parameters: ' + str(count_network_parameters(model)))\n",
    "    print(type(model))\n",
    "    \n",
    "    criterion = make_criterion(args)\n",
    "    optimizer = make_optimizer(args, model)\n",
    "    \n",
    "    fc_features = FCFeatures()\n",
    "    model.fc.register_forward_pre_hook(fc_features)\n",
    "    info_dict = {\n",
    "            'collapse_metric': [],\n",
    "            'ETF_metric': [],\n",
    "            'WH_relation_metric': [],\n",
    "            'Wh_b_relation_metric': [],\n",
    "            'W': [],\n",
    "            'b': [],\n",
    "            'H': [],\n",
    "            'mu_G_train': [],\n",
    "            # 'mu_G_test': [],\n",
    "            'train_acc1': [],\n",
    "            'train_acc5': [],\n",
    "            'test_acc1': [],\n",
    "            'test_acc5': []\n",
    "        }\n",
    "\n",
    "\n",
    "    for epoch_id in range(args.epochs):\n",
    "        trainer(args, model, trainloader, epoch_id, criterion, optimizer)\n",
    "        evaluater_NC(args,model,testloader,fc_features,info_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d599f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CIFAR10.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "# of model parameters: 11181642\n",
      "<class 'models.resnet.ResNet'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.82 GB, other allocations: 261.88 MB, max allowed: 9.07 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main(args)\n",
      "Cell \u001b[0;32mIn[40], line 41\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     23\u001b[0m info_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollapse_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETF_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc5\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     37\u001b[0m     }\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 41\u001b[0m     trainer(args, model, trainloader, epoch_id, criterion, optimizer)\n\u001b[1;32m     42\u001b[0m     evaluater_NC(args,model,testloader,fc_features,info_dict)\n",
      "Cell \u001b[0;32mIn[37], line 27\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(args, model, trainloader, epoch_id, criterion, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# measure accuracy and record loss\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/sgd.py:66\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m---> 66\u001b[0m         loss \u001b[38;5;241m=\u001b[39m closure()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m     69\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[37], line 14\u001b[0m, in \u001b[0;36mtrainer.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrossEntropy\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     17\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs[\u001b[38;5;241m0\u001b[39m], targets) \u001b[38;5;241m+\u001b[39m weight_decay(args, model)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Data_Distill_with_NC/models/resnet.py:289\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor):\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m~/Documents/GitHub/Data_Distill_with_NC/models/resnet.py:279\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    277\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 279\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    281\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    282\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Data_Distill_with_NC/models/resnet.py:70\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     69\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m---> 70\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    153\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.82 GB, other allocations: 261.88 MB, max allowed: 9.07 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84024096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_validate(config = None, args = args):\n",
    "    # Initial a new run\n",
    "    with wandb.init(config=config):\n",
    "        print(\"Initialise finished, starting now...\")\n",
    "        config = wandb.config\n",
    "        args.lr = config[\"learning_rate\"]\n",
    "        args.optimizer = config[\"optimizer\"]\n",
    "        args.batch_size = config[\"batch_size\"]\n",
    "        main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b40168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_validate(config = sweep_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a139bdd",
   "metadata": {},
   "source": [
    "# Start sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900332e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id,function=train_n_validate,count=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
